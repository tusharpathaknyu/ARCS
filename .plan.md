# Phase 3: Eulerian Circuit Representation + Architectural Alignment with README

## Goal
Refactor CircuitGenie from a **parameter-prediction model** (topology token + flat param list) to a **wiring-aware, value-embedded circuit generation model** using Eulerian walk representation, as described in the README. This brings the implementation in line with the architecture section of README.md.

## What Changes

### Current representation (parameter prediction)
```
<BOS> SPEC_V_IN VAL SPEC_V_OUT VAL ... <SEP> TOPO_BUCK <SEP> PARAM_L VAL PARAM_C VAL ... <EOS>
```
The model selects a topology label, then fills in parameter values. Wiring is **implicit** (hardcoded in SPICE templates). The model has zero awareness of how components connect.

### New representation (Eulerian walk with embedded values)
```
<BOS> SPEC_V_IN VAL SPEC_V_OUT VAL ... <SEP>
  GND S1_P GND D1_N D1_P SW L1_P L1_N OUT C1_P OUT RLOAD_P OUT RLOAD_N GND C1_N GND VIN_P INP VIN_N GND S1_CTRL VAL_duty S1_N SW
  L1 VAL_L C1 VAL_C RLOAD VAL_R_load VIN VAL_V_in S1 VAL_f_sw
<EOS>
```
The model generates the **circuit graph** as a node-by-node Eulerian walk (wiring), then **component values** in a sizing block. It learns topology from the walk structure, not from a label.

## Design Decisions

### 1. Hybrid sequence: Eulerian walk + value block
Rather than embedding values inside the walk (which would double walk length and break the Eulerian property), we split the sequence:
- **Walk section**: Pure topology/wiring — node tokens forming the Eulerian walk
- **Value section**: Component sizing — `COMP_NAME VAL_xxx` pairs

This keeps the walk clean for augmentation and lets the model attend from value positions back to the walk structure.

### 2. Node vocabulary
From the 7 SPICE templates, the distinct circuit nodes are:

| Node | Description | Topologies |
|------|-------------|------------|
| GND | Ground (0) | All |
| INP | Input voltage node | All |
| SW | Switch node | All |
| OUT | Output node | All |
| N1 | Internal node 1 | SEPIC, Cuk |
| N2 | Internal node 2 | SEPIC, Cuk |
| PRI | Primary node (transformer) | QR Flyback |
| SEC | Secondary node | Flyback, QR Flyback |

That's just **8 circuit node tokens**. Plus we need component-pin tokens for the walk. In AnalogGenie, each device pin is a separate token. For our power converters, the component pins are:

| Component | Pins | Present in |
|-----------|------|------------|
| S1 (switch) | P, N, CTRL | All |
| D1 (diode) | P, N | All |
| L1 (inductor) | P, N | Buck, Boost, Buck-Boost |
| L1_in (input inductor) | P, N | SEPIC, Cuk |
| L2 (output inductor) | P, N | SEPIC, Cuk |
| C1 (output cap) | P, N | Buck, Boost, Buck-Boost, Flyback, QR |
| Cc (coupling cap) | P, N | SEPIC, Cuk |
| Co (output cap) | P, N | SEPIC, Cuk |
| Rload | P, N | All |
| Vin (source) | P, N | All |
| Lpri (primary) | P, N | Flyback, QR |
| Lsec (secondary) | P, N | Flyback, QR |
| Lr (resonant) | P, N | QR Flyback |
| Cr (resonant cap) | P, N | QR Flyback |
| Dbody (body diode) | P, N | QR Flyback |

Rather than tokenizing individual pins, we use a **simpler approach**: each edge in the walk is `NODE_A COMP NODE_B` — meaning "component COMP connects node A to node B." This is more readable and still captures full topology. But this changes the walk from node-only to node-component-node triplets.

**Actually, let's follow AnalogGenie more closely**: the walk visits circuit nodes (not component pins), and each edge traversal implicitly represents a component. We can annotate edges:

Walk format: `NODE_i EDGE_COMP NODE_j EDGE_COMP NODE_k ...`

Example Buck: `GND → [S1] → SW → [L1] → OUT → [C1] → GND → [D1] → SW → [RLOAD] → OUT → [VIN] → INP → ...`

Encoded: `GND S1 SW L1 OUT C1 GND D1 SW RLOAD OUT VIN INP ...`

This interleaves node tokens and component tokens. The walk visits every edge (component) exactly once = Eulerian.

### 3. New Vocabulary (~197 tokens)

```
Special:        PAD, BOS, EOS, SEP              (4)
Node tokens:    GND, INP, SW, OUT, N1, N2,      (8)
                PRI, SEC
Component tokens: S1, D1, L1, C1, RLOAD, VIN,   (15)
                  L1_IN, L2, CC, CO, LPRI, LSEC,
                  LR, CR, DBODY
Spec tokens:    SPEC_V_IN ... SPEC_EFF           (5)
Param tokens:   PARAM_L ... PARAM_V_OUT          (13) (reuse for value block)
Value bins:     VAL_000 ... VAL_127              (128)
Walk marker:    WALK_END                         (1)
                                          Total: ~174
```

Actually we can simplify. The walk section already identifies components by name. The value section just needs `COMP_NAME VAL_xxx` pairs. So we reuse component tokens in both sections. Let me refine:

```
Special (5):     PAD, BOS, EOS, SEP, WALK_END
Node (8):        N_GND, N_INP, N_SW, N_OUT, N_N1, N_N2, N_PRI, N_SEC
Component (15):  C_S1, C_D1, C_L1, C_C1, C_RLOAD, C_VIN,
                 C_L1IN, C_L2, C_CC, C_CO, C_LPRI, C_LSEC,
                 C_LR, C_CR, C_DBODY
Spec names (5):  SPEC_V_IN, SPEC_V_OUT, SPEC_I_OUT, SPEC_RIPPLE, SPEC_EFF
Value bins (128): VAL_000 ... VAL_127
                                          Total: 161 tokens
```

### 4. Sequence format

```
<BOS>
  [Spec block: SPEC_V_IN VAL SPEC_V_OUT VAL ... ]
<SEP>
  [Eulerian walk: N_GND C_S1 N_SW C_L1 N_OUT C_C1 N_GND C_D1 N_SW ...]
<WALK_END>
  [Value block: C_L1 VAL C_C1 VAL C_RLOAD VAL C_VIN VAL C_S1 VAL_duty C_S1 VAL_fsw]
<EOS>
```

### 5. Eulerian walk construction per topology

For each topology, extract the component graph from SPICE templates, find an Eulerian circuit (Hierholzer's algorithm), and generate the walk. For data augmentation, generate multiple random Eulerian walks from the same graph (different starting nodes, different edge orderings).

### 6. Max sequence length

Longest topology (QR Flyback): 10 components × 2 tokens per edge in walk = ~20 walk tokens + 11 spec tokens + ~14 value tokens + 4 structural = ~49 tokens.

Raise max_seq_len from 32 → 64.

### 7. Model changes
- `config.py`: vocab_size from 157→161, max_seq_len from 32→64
- Model stays the same architecture (GPT decoder), just bigger context
- Bump d_model 128→256, n_layers 4→6 for more capacity (~6M params, still tiny)
- Can revisit 50-100M target later when we add more circuit families

### 8. Invalid examples
The README says "keep failures too." We generate random circuits, simulate, and if SPICE fails or V_out is wildly wrong, label them `is_valid=False` and include them with a `VALID`/`INVALID` prefix token. The model learns what NOT to do.

## Implementation Steps

### Step 1: Build circuit graph representations (`circuitgenie/data/circuit_graph.py`)
- Define `CircuitGraph` dataclass: nodes, edges (node_a, component, node_b)
- Build graph for each of the 7 topologies from SPICE templates
- Implement Hierholzer's algorithm for Eulerian walk generation
- Support multiple random walks per graph (augmentation)
- Unit test: verify each topology produces valid Eulerian walk that covers all edges

### Step 2: Redesign vocabulary (`circuitgenie/tokenizer/vocabulary_v2.py`)
- New token set: special + node + component + spec + value bins
- Keep `vocabulary.py` intact (v1 still works for old checkpoints)
- Node-to-ID and component-to-ID mappings
- Same value binning functions (reuse from v1)

### Step 3: Redesign sequence encoding (`circuitgenie/tokenizer/sequence_v2.py`)
- `circuit_to_tokens_v2()`: spec block + Eulerian walk + value block
- `tokens_to_circuit_v2()`: decode back to topology, params, specs
- `tokens_to_netlist_v2()`: decode walk → identify topology → fill SPICE template
- Walk augmentation: N different Eulerian walks per sample

### Step 4: Update tokenizer (`circuitgenie/tokenizer/tokenizer_v2.py`)
- `CircuitTokenizerV2` wrapping the new encode/decode
- `max_seq_len=64`

### Step 5: Update dataset with augmentation + invalid examples (`circuitgenie/training/dataset_v2.py`)
- Each sample → N augmented walks (e.g., 5-10 walks per circuit = 5-10× data)
- Include invalid/failed circuits with `is_valid=False` flag
- Generate fresh invalid samples by random parameter generation + SPICE simulation

### Step 6: Update model config (`circuitgenie/model/config.py`)
- New config preset for v2: vocab_size=161, max_seq_len=64, d_model=256, n_layers=6, n_heads=8, d_ff=1024
- ~6.5M params (8× bigger than v1 but still runs on M3 in minutes)

### Step 7: Training script (`scripts/train_v3.py`)
- Stage 1: CE pre-training with Eulerian walk sequences + augmented data
- Stage 2: REINFORCE with SPICE reward (reuse rl_trainer.py with minor adaptations)
- Generate data with augmentation: 35K base × 5 walks = 175K training sequences
- Compare v2 (Eulerian) vs v1 (flat params) on same evaluation suite

### Step 8: Update evaluation (`circuitgenie/training/evaluate.py`)
- Adapt evaluate_model to work with v2 tokenizer
- Add topology inference test (model should pick correct topology from walk structure alone, no TOPO_xxx label)
